# ComfyUI-Ollama-Enhancer ðŸš€

Custom [ComfyUI](https://github.com/comfyanonymous/ComfyUI) nodes powered by [Ollama](https://ollama.ai)  
to automatically **generate and refine positive/negative prompts** for diffusion models like **Stable Diffusion XL** and **Flux**.

---

## âœ¨ Features

- ðŸ”¹ Automatic **positive & negative prompt generation** via Ollama  
- ðŸ”¹ Compatible with **Stable Diffusion XL** and **Flux** models  
- ðŸ”¹ Connects to **local or remote Ollama endpoints** (`http://localhost:11434` or your server)  
- ðŸ”¹ Produces ready-to-use **encoded outputs** for seamless workflow integration  
- ðŸ”¹ Optional **CPU mode** to save VRAM  
- ðŸ”¹ Simple, plug-and-play integration with existing ComfyUI pipelines  

---

## ðŸŽ¨ Workflow example in ComfyUI
![workflow](docs/workflow.png)

---

## ðŸ“¦ Installation for Comfyui

Clone this repo inside your ComfyUI `custom_nodes` folder:

```bash
# Step 1 â€“ go to the folder where you keep custom nodes for ComfyUI
cd ComfyUI/custom_nodes

# Step 2 â€“ clone your copy of the Ollamaâ€‘Enhancer node from GitHub
git clone https://github.com/<your-username>/ComfyUI-Ollama-Enhancer.git

# Step 3 â€“ change into the newlyâ€‘cloned repository
cd ComfyUI-Ollama-Enhancer

# Step 4 â€“ install the Python dependencies listed in requirements.txt
# (the file is automatically generated by uv, but we keep it for compatibility)
pip install -r requirements.txt
```

## ðŸ“¦ Installation for local dev

```bash
mise trust .mise.toml
mise run setup-dev 
mise run test
```
